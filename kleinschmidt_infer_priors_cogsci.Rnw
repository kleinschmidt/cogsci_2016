\documentclass[10pt,letterpaper]{article}

\usepackage{cogsci}
\usepackage{pslatex}
\usepackage{apacite}
\usepackage{siunitx}
\usepackage{dcolumn}

\usepackage{subcaption}

\usepackage{tipx}
\newcommand{\ph}[1]{\protect\textipa{/#1/}}
\newcommand{\aph}[1]{\protect\textipa{[#1]}}

\newcommand{\ms}[1]{\SI{#1}{\milli\second}}

\title{What do you expect from an unfamiliar talker?}
 
\author{{\large \bf Dave F. Kleinschmidt$^1$}, and 
   {\large \bf T. Florian Jaeger$^{1,2,3}$} \\
   \texttt{\{dkleinschmidt, fjeager\} $@$ bcs.rochester.edu} \\
  $^1$Department of Brain and Cognitive Sciences, $^2$Department of Computer Science, and $^3$Department of Linguistics, \\
  University of Rochester, Rochester, NY, 14607 USA}


\begin{document}

\maketitle

\begin{abstract}
\textbf{Keywords:} Cognitive Science, Linguistics, Psychology, Language understanding, Learning, Speech recognition
\end{abstract}



<<preamble, echo=FALSE, results='hide', warning=FALSE, message=FALSE>>=

knitr::opts_chunk$set(echo=FALSE,
                      results='hide',
                      message=FALSE,
                      warning=FALSE,
                      error=FALSE)

library(supunsup)

library(dplyr)
library(tidyr)
library(magrittr)

data <- supunsup::supunsup_clean %>%
  filter(supCond == 'unsupervised') %>%
  mutate(subjNum = as.numeric(factor(subject)),
         trueCatNum = as.numeric(trueCat),
         respCatNum = as.numeric(respCat))

library(ggplot2)
theme_set(theme_bw())

library(lme4)

@



\section{Experiment}
\label{sec:experiment}

\subsection{Methods}
\label{sec:methods}

\subsubsection{Subjects}
\label{sec:subjects}

<<participants>>=
n_subj <- data %>% group_by(subject) %>% summarise() %>% tally()

excluded <- supunsup::supunsup_excluded %>%
  filter(supCond == 'unsupervised') %>%
  group_by(subject) %>% 
  summarise() %>% 
  right_join(supunsup::excludes) %>%
  select(subject, exclude80PercentAcc, rank)

n_excluded <- nrow(excluded)
n_subj_repeat <- sum(!is.na(excluded$rank))
n_subj_bad <- sum(!is.na(excluded$exclude80PercentAcc))
n_both <- n_subj_repeat + n_subj_bad - n_excluded 

n_total <- n_subj + n_excluded

@ 

We recruited \Sexpr{n_total} subjects via Amazon's Mechanical Turk, who were
paid \$2.00 for participation, which took about 20 minutes. We excluded subjects
who participated more than once ($n=\Sexpr{n_subj_repeat}$) or whose accuracy at
\ms{0} and \ms{70} VOT---as extrapolated via a logistic GLM---was less than 80\%
correct ($n=\Sexpr{n_subj_bad}$; $n=\Sexpr{n_both}$ for both reasons). After
these exclusions, data from \Sexpr{n_subj} subjects remained for analysis for
analysis.

\subsubsection{Procedure}
\label{sec:procedure}

\begin{figure}
  \centering
  \includegraphics[width=\columnwidth]{figure_manual/beach_peach.png}
  \caption{Example trial display (beach/peach). Listeners first click on the
    green button to play the word, then click on one picture to indicate what
    they heard.}
  \label{fig:beach-peach}
\end{figure}


\begin{figure*}[]
\centering

<<input-vs-prior-stats, fig.width=8, fig.height=2, out.width="\\textwidth">>=

## copied from NIPS paper #######################################

## prior parameters from Kronrod et al. (CogSci 2012)
prior_stats <- data.frame(category=factor(c('b', 'p')),
                          mean = c(0, 60),
                          sd = sqrt(c(14, 254)))

exposure_stats <- data %>%
  group_by(bvotCond, category=trueCat) %>%
  summarise(mean=mean(vot), sd=sd(vot))

sd_noise = sqrt(82)

stats_to_lhood <- function(stats, noise_sd=sd_noise) {
  stats %>%
    group_by(category, mean, sd) %>%
    do(data.frame(vot=seq(-30, 90, 0.5))) %>%
    ungroup() %>%
    mutate(lhood = dnorm(vot, mean, sqrt(sd^2 + noise_sd^2))) %>%
    select(-mean, -sd)
}

exposure_lhood <- exposure_stats %>%
  group_by(bvotCond) %>%
  do(stats_to_lhood(., sd_noise))

prior_lhood <- prior_stats %>% stats_to_lhood(sd_noise)

data %>%
  group_by(bvotCond, vot) %>%
  filter(subject == first(subject)) %>%
  tally() %>%
  ggplot(aes(x=vot)) +
  geom_bar(stat='identity', aes(y=n, fill=bvotCond)) +
  geom_line(data=prior_lhood, aes(y=lhood*1600, group=category),
            color="black", linetype=2) +
  geom_text(data=data.frame(bvotCond=-10), x = 10, y = 60,
            label = 'Typical Talker',
            color='black', hjust=0, vjust=0.3, size=3) +
  geom_text(data=data.frame(bvotCond=-10), x = 40, y = 50,
            label = 'Exposure\nTalker',
            color=hcl(h=15, c=100, l=65), hjust=0, vjust=0.8, size=3,
            lineheight=1) + 
  facet_grid(.~bvotCond) +
  scale_x_continuous('VOT (ms)') +
  scale_y_continuous('Frequency') +
  scale_fill_discrete('/b/ mean\nVOT') +
  theme(legend.position='none')

@ 

\caption{Each subject heard one of these five synthetic accents, which differ
  only in the distribution of VOTs of the word-initial stops. Black dashed lines
  show VOT distributions from a hypothetical typical talker (as estimated by
  \citeNP{Kronrod2012}). Note that the 0 and 10ms shifted accents are reasonably
  close to this typical talker, while the $-10$, 20, and 30ms shifted accents
  deviate substantially.}
\label{fig:vot-dists}

\end{figure*}

Our distributional learning procedure is described in \citeA{Kleinschmidt2015a},
and is based on \citeA{Clayards2008}. On each trial, two response option images
appeard, which corresponded to one of three /b/-/p/ minimal pairs (beach/peach,
bees/peas, or beak/peak). Subjects then clicked on a central button which played
the corresponding minimal pair word, and then clicked on the picture to indicate
whether they heard the /b/ or /p/ member of the minimal pair.  Subjects
performed 222 of these trials.

Each trial's word was synthesized with a voice onset time (VOT) that was
randomly drawn from a bimodal distribution, with low and high VOT clusters
implicitly corresponding to /b/ and /p/, respectively.  This distribution
defined the \emph{accent} that the subject heard, and each subject was
pseudorandomly assigned to one of five accent conditions
(Figure~\ref{fig:vot-dists}).

\subsection{Results}
\label{sec:results}

<<regression, eval=FALSE>>=
data_lmer <- supunsup::mutate_for_lmer(data)

## double check that contrasts are helmert coded...
contrasts(data_lmer$bvotCond)

## basically anything more than this doesn't converge...
mod <- glmer(respP ~ vot_rel.s * trial.s + bvotCond + (1 | subject),
             data_lmer, family='binomial')

@ 

\begin{figure*}
  \centering

<<class-curves, fig.height=2, fig.width=8, out.width="\\textwidth">>=
## generate predicted classification functions assuming Bayes-optimal classifier
## + noise

lhood_to_classification <- function(lhood) {
  lhood %>%
    spread(category, lhood) %>%
    mutate(prob_p = p / (p+b))
}

perfect_learning <- exposure_stats %>%
  group_by(bvotCond) %>%
  do(stats_to_lhood(.)) %>%
  lhood_to_classification

no_learning <- prior_stats %>%
  stats_to_lhood %>%
  lhood_to_classification

prior_bound <- no_learning %>%
  arrange(abs(prob_p - 0.5)) %>%
  filter(row_number() ==1) %$%
  vot


boundaries <- data %>%
  group_by(bvotCond, subject) %>%
  do({ glm(respP ~ vot, family='binomial', data=.) %>%
         broom::tidy() %>%
         select(term, estimate)
  }) %>%
  ungroup() %>%
  spread(term, estimate) %>%
  mutate(boundary = -`(Intercept)` / vot,
         ideal_boundary = as.numeric(as.character(bvotCond)) + 20,
         prior_boundary = prior_bound,
         prop_shift = (boundary-prior_boundary)/(ideal_boundary-prior_boundary))

boundary_summary <- boundaries %>%
  group_by(bvotCond) %>%
  summarise(median_shift_perc = round(100*median(prop_shift)),
            shift_text = paste(median_shift_perc, '%', sep='')) %>%
  filter(bvotCond != 0)                 # basically no shift possible


ggplot(data, aes(x=vot, y=respP, color=bvotCond)) +
  geom_line(aes(group=subject), stat='smooth', method='glm', family='binomial', alpha=0.2) +
  facet_grid(.~bvotCond) +
  geom_line(data=perfect_learning, aes(y=prob_p), group=1, linetype=2, size=1) +
  geom_line(data=no_learning, aes(y=prob_p), group=1, linetype=2, color='black') +
  geom_text(data=data.frame(bvotCond=-10),
            x = 30, y = 0, label = 'Typical\ntalker',
            size = 3.5, hjust=0, vjust = 0, color='black',
            lineheight=1) + 
  geom_text(data=data.frame(bvotCond=-10),
            x = 12, y = 1, label = 'Expo-\nsure',
            size = 3.5, hjust=1, vjust=1, color=hcl(15, c=100, l=65),
            lineheight=1, fontface='bold') + 
  geom_text(data=data.frame(bvotCond=-10),
            x = 90, y = 0.75, label = 'Actual\nlisteners',
            size = 3.5, hjust=1, vjust=1, color=hcl(15, c=100, l=65),
            lineheight=1) + 
  ## geom_text(data=boundary_summary, aes(x=75, y=0.1, label=shift_text), color='black') + 
  theme(legend.position='none') +
  scale_x_continuous('VOT (ms)') +
  scale_y_continuous('Probability /p/ response') + 
  scale_color_discrete('/b/ mean\nVOT')


@ 
  
\caption{Listeners' responses, smoothed with logistic functions (thin lines),
  compared with the classification functions expected based on a typical talker
  (no learning; dashed black lines) and complete adaptation to the exposure
  distributions (thick dashed colored lines). Listeners' actual category
  boundaries lie between the typical talker and exposure talker boundaries.}
\label{fig:class-curves}
\end{figure*}

Figure~\ref{fig:class-curves} shows the classification functions for each
individual listener. In each accent, these classification functions tend to fall
in between the boundaries predicted by the typical talker distributions and the
boundaries implied by the exposure distributions.  Moreover, in the

\subsection{Discussion}
\label{sec:discussion}




\section{Model}
\label{sec:model}


\section{Conclusion}
\label{sec:conclusion}



\bibliographystyle{apacite}

\setlength{\bibleftmargin}{.125in}
\setlength{\bibindent}{-\bibleftmargin}

\bibliography{/Users/dkleinschmidt/Documents/papers/library-clean}



\end{document}
